{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy       # python wrapper for twitter api\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "# step 0, get your own twitter credentials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is my own personal twitter api information\n",
    "# if you could be so kind as to sign up yourself on both twitter and mashape that'd be great :)\n",
    "# It's FREEEEEEE\n",
    "api_key = 'g5uPIpw80nULQI1gfklv2zrh4'\n",
    "api_secret = 'cOWvNWxYvPmEZ0ArZVeeVVvJu41QYHdUS2GpqIKtSQ1isd5PJy'\n",
    "access_token = '49722956-TWl8J0aAS6KTdcbz3ppZ7NfqZEmrwmbsb9cYPNELG'\n",
    "access_secret = '3eqrVssF3ppv23qyflyAto8wLEiYRA8sXEPSghuOJWTub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Documentation is your friend! http://docs.tweepy.org/en/v3.1.0/\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth) # returns a tweepy authorization handler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Use Twitter API to stream and store tweets (300 per candidate)\n",
    "# 37.781157,-122.39872 is the lat,lng for SF\n",
    "hilary_tweets = api.search(q='#ImWithHer', count=100, geocode=\"37.781157,-122.398720,10mi\") + api.search(q='#hillaryclinton', count=100, geocode=\"37.781157,-122.398720,50mi\") + api.search(q='#hillary2016', count=100, geocode=\"37.781157,-122.398720,50mi\")\n",
    "the_donald_tweets = api.search(q='#donaldtrump', count=100, geocode=\"37.781157,-122.398720,10mi\") + api.search(q='#trump2016', count=100, geocode=\"37.781157,-122.398720,50mi\") + api.search(q='#trump', count=100, geocode=\"37.781157,-122.398720,50mi\") + api.search(q='#makeamericagreatagain', count=100, geocode=\"37.781157,-122.398720,50mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"RT @JacloPac: #DonaldTrump's racist antisemitic fascists now running his campaign use #AltRight as a rebranding of #AltReich. https://t.co/\\u2026\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_donald_tweets[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"RT @JenGranholm: Trump's Pants on Fire claim that he 'finished' the Obama birther talk https://t.co/LZMAlolkWZ #NeverTrump @HillaryClinton\\u2026\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hilary_tweets[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__eq__', '__format__', '__getattribute__', '__getstate__', '__hash__', '__init__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at', 'destroy', 'entities', 'extended_entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place', 'possibly_sensitive', 'retweet', 'retweet_count', 'retweeted', 'retweeted_status', 'retweets', 'source', 'source_url', 'text', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "# wrappers come with built in python attributes and methods!\n",
    "print dir(the_donald_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-17 16:29:12\n",
      "RT @JacloPac: #DonaldTrump's racist antisemitic fascists now running his campaign use #AltRight as a rebranding of #AltReich. https://t.co/â€¦\n",
      "0\n",
      "False\n",
      "en\n",
      "None\n",
      "45\n",
      "False\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print the_donald_tweets[0].created_at\n",
    "print the_donald_tweets[0].text\n",
    "print the_donald_tweets[0].favorite_count\n",
    "print the_donald_tweets[0].favorited\n",
    "print the_donald_tweets[0].lang\n",
    "print the_donald_tweets[0].geo\n",
    "print the_donald_tweets[0].retweet_count\n",
    "print the_donald_tweets[0].retweeted\n",
    "print the_donald_tweets[0].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify the tweets to make a nice dictionary\n",
    "def parse_status_objects(tweet_list):\n",
    "    modified_tweets = list()\n",
    "    for x in tweet_list:\n",
    "        modified_tweets.append( [\n",
    "                    x.created_at,\n",
    "                    x.text,\n",
    "                    x.favorite_count,\n",
    "                    x.favorited,\n",
    "                    x.lang,\n",
    "                    x.geo,\n",
    "                    x.retweet_count,\n",
    "                    x.retweeted,\n",
    "                    x.coordinates\n",
    "                ])\n",
    "    return modified_tweets\n",
    "        \n",
    "hilary_tweets = parse_status_objects(hilary_tweets)\n",
    "the_donald_tweets = parse_status_objects(the_donald_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2016, 9, 17, 16, 29, 12), u\"RT @JacloPac: #DonaldTrump's racist antisemitic fascists now running his campaign use #AltRight as a rebranding of #AltReich. https://t.co/\\u2026\", 0, False, u'en', None, 45, False, None]\n",
      "[datetime.datetime(2016, 9, 17, 16, 46, 9), u\"RT @JenGranholm: Trump's Pants on Fire claim that he 'finished' the Obama birther talk https://t.co/LZMAlolkWZ #NeverTrump @HillaryClinton\\u2026\", 0, False, u'en', None, 119, False, None]\n"
     ]
    }
   ],
   "source": [
    "print the_donald_tweets[0]\n",
    "print hilary_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 Create a dataframe that combines all of the tweets from each candidate\n",
    "# To do so, you will need to concat the data frames\n",
    "# so each row is a tweet and your columns should be \n",
    "# date, text, favorite_count,favorited, language, geocode, retweet count, retweeted, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 Create a function to take in a string and output the textblob sentiment of that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Add a column to your data frame called 'sentiment'\n",
    "# which holds the sentiment of that tweet (hint: use the function from #3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 create a word count column, which holds the number of words in the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use countvectorizer to create a document-term matrix and concatinate it to your main dataframe\n",
    "#(hint you should now have thousands of columns)\n",
    "# Don't add count vectorizer result to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6 Use kmean to create clusters for the dataframe (choose an optimal k)\n",
    "# Don't add clusters to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7 Explore the clusters\n",
    "# What is interesting? Surprising? Can you draw any inferences about each cluster?\n",
    "# Write your answer to these questions in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8 Create a column called 'democrat' and assign it to the corresponding candidate name for all the records\n",
    "# 1 for hilary and 0 for donald trump\n",
    "# Make a boxplot of sentiment for each candidate by the \"democrat\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9 Estimate classification models using knn and logistic regession.  Dont forget to use cross validation \n",
    "    # (do not use cross_val_score because we will want a confusion matrix).\n",
    "# The cateogrical response here is predict democrat or republican\n",
    "# Your features can EITHER be your countvectorizer document term matrix OR \n",
    "# data from the original dataframe (sentiment, word count, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10 Initialize a classification model (for both knn and logistic)\n",
    "# This is separate from step 9 because I will eventually want a \n",
    "# confusion matrix and we can't do that via cros validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11 Split your data into training and testing tests and then\n",
    "# train your classification model  (for both knn and logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 12 Predict on your test features and targets (for both knn and logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 13 output your accuracy (for both knn and logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 14 Create a confusion matrix for your predictions (for both knn and logistic)\n",
    "# What is the sensitivity and specificity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 15 Who is the easiest candidate to predict? Why do you think? \n",
    "# Who is the hardest? Why do you think?\n",
    "# Write your answers in markdown (for both knn and logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 16 BONUS: make a pipeline with the first step being a feature union of countvectorizer\n",
    "# and tfidfvectorizer and no other features and our second step is\n",
    "# a ML model (your choice) predict our binary response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 17: BONUS: grid search the model in step 16 to obtain the best features (up to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 18: SUPER BONUS: make a custom transformer that extracts sentiment and word count\n",
    "# make a pipeline that combines countvec, tfidfvec and your custom transformer\n",
    "# and try to get the possible accuracy for predicting whether or not the person is talking\n",
    "# about democrats or republicans"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [sfdat26-env]",
   "language": "python",
   "name": "Python [sfdat26-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
